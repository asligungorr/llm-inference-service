LLM Inference ML Service

This project provides a simple ML inference service built with FastAPI.
